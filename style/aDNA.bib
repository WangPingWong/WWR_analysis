
@article{ralfYleafSoftwareHuman2018,
  title = {Yleaf: {{Software}} for {{Human Y}}-{{Chromosomal Haplogroup Inference}} from {{Next}}-{{Generation Sequencing Data}}},
  shorttitle = {Yleaf},
  author = {Ralf, Arwin and González, Diego Montiel and Zhong, Kaiyin and Kayser, Manfred},
  date = {2018-07-01},
  journaltitle = {Molecular Biology and Evolution},
  shortjournal = {Mol Biol Evol},
  volume = {35},
  pages = {1820--1820},
  publisher = {{Oxford Academic}},
  issn = {0737-4038},
  doi = {10.1093/molbev/msy080},
  url = {https://academic.oup.com/mbe/article/35/7/1820/4993044},
  urldate = {2020-12-03},
  abstract = {Molecular Biology and Evolution, msy032, https://doi.org/10.1093/molbev/msy032},
  langid = {english},
  number = {7}
}




@online{garrisonHaplotypebasedVariantDetection2012b,
  title = {Haplotype-Based Variant Detection from Short-Read Sequencing},
  author = {Garrison, Erik and Marth, Gabor},
  date = {2012-07-20},
  url = {http://arxiv.org/abs/1207.3907},
  urldate = {2021-01-12},
  abstract = {The direct detection of haplotypes from short-read DNA sequencing data requires changes to existing small-variant detection methods. Here, we develop a Bayesian statistical framework which is capable of modeling multiallelic loci in sets of individuals with non-uniform copy number. We then describe our implementation of this framework in a haplotype-based variant detector, FreeBayes.},
  archivePrefix = {arXiv},
  eprint = {1207.3907},
  eprinttype = {arxiv},
  keywords = {Quantitative Biology - Genomics,Quantitative Biology - Quantitative Methods},
  note = {Comment: 9 pages, partial draft},
  primaryClass = {q-bio}
}


@article{ditommasoNextflowEnablesReproducible2017,
  title = {Nextflow Enables Reproducible Computational Workflows},
  author = {Di Tommaso, Paolo and Chatzou, Maria and Floden, Evan W. and Barja, Pablo Prieto and Palumbo, Emilio and Notredame, Cedric},
  date = {2017-04-11},
  journaltitle = {Nature Biotechnology},
  volume = {35},
  pages = {316--319},
  issn = {1546-1696},
  doi = {10.1038/nbt.3820},
  url = {https://www.nature.com/articles/nbt.3820},
  urldate = {2018-12-02},
  abstract = {Nextflow enables reproducible computational workflows},
  langid = {english}
}

@article{jacksonUsingRapidPrototyping2020,
  title = {Using Rapid Prototyping to Choose a Bioinformatics Workflow Management System},
  author = {Jackson, Michael J. and Wallace, Edward and Kavoussanakis, Kostas},
  date = {2020-08-05},
  journaltitle = {bioRxiv},
  pages = {2020.08.04.236208},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2020.08.04.236208},
  url = {https://www.biorxiv.org/content/10.1101/2020.08.04.236208v1},
  urldate = {2020-10-22},
  abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}Workflow management systems represent, manage, and execute multi-step computational analyses and offer many benefits to bioinformaticians. They provide a common language for describing analysis workflows, contributing to reproducibility and to building libraries of reusable components. They can support both incremental build and re-entrancy – the ability to selectively re-execute parts of a workflow in the presence of additional inputs or changes in configuration and to resume execution from where a workflow previously stopped. Many workflow management systems enhance portability by supporting the use of containers, high-performance computing systems and clouds. Most importantly, workflow management systems allow bioinformaticians to delegate \emph{how} their workflows are run to the workflow management system and its developers. This frees the bioinformaticians to focus on the content of these workflows, their data analyses, and their science.{$<$}/p{$><$}p{$>$}RiboViz is a package to extract biological insight from ribosome profiling data to help advance understanding of protein synthesis. At the heart of RiboViz is an analysis workflow, implemented in a Python script. To conform to best practices for scientific computing which recommend the use of build tools to automate workflows and to re-use code instead of rewriting it, the authors reimplemented this workflow within a workflow management system. To select a workflow management system, a rapid survey of available systems was undertaken, and candidates were shortlisted: Snakemake, cwltool and Toil (implementations of the Common Workflow Language) and Nextflow. An evaluation of each candidate, via rapid prototyping of a subset of the RiboViz workflow, was performed and Nextflow was chosen. The selection process took 10 person-days, a small cost for the assurance that Nextflow best satisfied the authors’ requirements. This use of rapid prototyping can offer a low-cost way of making a more informed selection of software to use within projects, rather than relying solely upon reviews and recommendations by others.{$<$}/p{$><$}h3{$>$}Author summary{$<$}/h3{$>$} {$<$}p{$>$}Data analysis involves many steps, as data are wrangled, processed, and analysed using a succession of unrelated software packages. Running all the right steps, in the right order, with the right outputs in the right places is a major source of frustration. Workflow management systems require that each data analysis step be “wrapped” in a structured way, describing its inputs, parameters, and outputs. By writing these wrappers the scientist can focus on the meaning of each step, which is the interesting part. The system uses these wrappers to decide what steps to run and how to run these, and takes charge of running the steps, including reporting on errors. This makes it much easier to repeatedly run the analysis and to run it transparently upon different computers. To select a workflow management system, we surveyed available tools and selected three for “rapid prototype” implementations to evaluate their suitability for our project. We advocate this rapid prototyping as a low-cost (both time and effort) way of making an informed selection of a system for use within a project. We conclude that many similar multi-step data analysis workflows can be rewritten in a workflow management system.{$<$}/p{$>$}},
  langid = {english}
}

@article{yatesReproduciblePortableEfficient2020,
  title = {Reproducible, Portable, and Efficient Ancient Genome Reconstruction with Nf-Core/Eager},
  author = {Yates, James A. Fellows and Lamnidis, Thiseas C. and Borry, Maxime and Valtueña, Aida Andrades and Fagernäs, Zandra and Clayton, Stephen and Garcia, Maxime U. and Neukamm, Judith and Peltzer, Alexander},
  date = {2020-10-21},
  journaltitle = {bioRxiv},
  pages = {2020.06.11.145615},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2020.06.11.145615},
  url = {https://www.biorxiv.org/content/10.1101/2020.06.11.145615v2},
  urldate = {2020-11-23},
  abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}The broadening utilisation of ancient DNA to address archaeological, palaeontological, and biological questions is resulting in a rising diversity in the size of laboratories and scale of analyses being performed. In the context of this heterogeneous landscape, we present nf-core/eager, an advanced and entirely redesigned and extended version of the EAGER pipeline for the analysis of ancient genomic data. This Nextflow pipeline aims to address three main themes: accessibility and adaptability to different computing configurations, reproducibility to ensure robust analytical standards, and updating the pipeline to the latest routine ancient genomic practises. This new version of EAGER has been developed within the nf-core initiative to ensure high-quality software development and maintenance support; contributing to a long-term lifecycle for the pipeline. nf-core/eager will assist in ensuring that ancient DNA sequencing data can be used by a diverse range of research groups and fields.{$<$}/p{$>$}},
  langid = {english}
}


@article{langmeadFastGappedreadAlignment2012,
  title = {Fast gapped-read alignment with Bowtie 2},
  author = {Langmead, Ben and Salzberg, Steven L.},
  date = {2012-04},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Meth},
  volume = {9},
  pages = {357-359},
  issn = {1548-7091},
  doi = {10.1038/nmeth.1923},
  url = {http://www.nature.com/nmeth/journal/v9/n4/abs/nmeth.1923.html},
  urldate = {2016-05-23},
  abstract = {As the rate of sequencing increases, greater throughput is demanded from read aligners. The full-text minute index is often used to make alignment very fast and memory-efficient, but the approach is ill-suited to finding longer, gapped alignments. Bowtie 2 combines the strengths of the full-text minute index with the flexibility and speed of hardware-accelerated dynamic programming algorithms to achieve a combination of high speed, sensitivity and accuracy.},
  keywords = {Bioinformatics,Genomics,sequencing},
  langid = {english},
  number = {4}
}

@article{sadedinBazamRapidMethod2019a,
  title = {Bazam: A Rapid Method for Read Extraction and Realignment of High-Throughput Sequencing Data},
  shorttitle = {Bazam},
  author = {Sadedin, Simon P. and Oshlack, Alicia},
  date = {2019-04-18},
  journaltitle = {Genome Biology},
  shortjournal = {Genome Biology},
  volume = {20},
  pages = {78},
  issn = {1474-760X},
  doi = {10.1186/s13059-019-1688-1},
  url = {https://doi.org/10.1186/s13059-019-1688-1},
  urldate = {2020-11-25},
  abstract = {The vast quantities of short-read sequencing data being generated are often exchanged and stored as aligned reads. However, aligned data becomes outdated as new reference genomes and alignment methods become available. Here we describe Bazam, a tool that efficiently extracts the original paired FASTQ from alignment files (BAM or CRAM format) in a format that directly allows efficient realignment. Bazam facilitates up to a 90\% reduction in the time for realignment compared to standard methods. Bazam can support selective extraction of read pairs from focused genomic regions for applications such as targeted region analyses, quality control, structural variant calling, and alignment comparisons.},
  number = {1}
}

@article{tischlerBiobambamToolsRead2014,
  title = {Biobambam: Tools for Read Pair Collation Based Algorithms on {{BAM}} Files},
  shorttitle = {Biobambam},
  author = {Tischler, German and Leonard, Steven},
  date = {2014-06-20},
  journaltitle = {Source Code for Biology and Medicine},
  shortjournal = {Source Code for Biology and Medicine},
  volume = {9},
  pages = {13},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-9-13},
  url = {https://doi.org/10.1186/1751-0473-9-13},
  urldate = {2020-11-25},
  abstract = {Sequence alignment data is often ordered by coordinate (id of the reference sequence plus position on the sequence where the fragment was mapped) when stored in BAM files, as this simplifies the extraction of variants between the mapped data and the reference or of variants within the mapped data. In this order paired reads are usually separated in the file, which complicates some other applications like duplicate marking or conversion to the FastQ format which require to access the full information of the pairs.},
  number = {1}
}


@article{kawashARIADNAMachineLearning2018,
  title = {{{ARIADNA}}: Machine Learning Method for Ancient {{DNA}} Variant Discovery},
  shorttitle = {{{ARIADNA}}},
  author = {Kawash, Joseph K and Smith, Sean D and Karaiskos, Spyros and Grigoriev, Andrey},
  date = {2018-12},
  journaltitle = {DNA Research: An International Journal for Rapid Publication of Reports on Genes and Genomes},
  shortjournal = {DNA Res},
  volume = {25},
  pages = {619--627},
  issn = {1340-2838},
  doi = {10.1093/dnares/dsy029},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6289774/},
  urldate = {2020-10-09},
  abstract = {Ancient DNA (aDNA) studies often rely on standard methods of mutation calling, optimized for high-quality contemporary DNA but not for excessive contamination, time- or environment-related damage of aDNA. In the absence of validated datasets and despite showing extreme sensitivity to aDNA quality, these methods have been used in many published studies, sometimes with additions of arbitrary filters or modifications, designed to overcome aDNA degradation and contamination problems. The general lack of best practices for aDNA mutation calling may lead to inaccurate results. To address these problems, we present ARIADNA (ARtificial Intelligence for Ancient DNA), a novel approach based on machine learning techniques, using specific aDNA characteristics as features to yield improved mutation calls. In our comparisons of variant callers across several ancient genomes, ARIADNA consistently detected higher-quality genome variants with fast runtimes, while reducing the false positive rate compared with other approaches.},
  eprint = {30215675},
  eprinttype = {pmid},
  number = {6},
  pmcid = {PMC6289774}
}

@article{pruferSnpADAncientDNA2018,
  title = {{{snpAD}}: An Ancient {{DNA}} Genotype Caller},
  shorttitle = {{{snpAD}}},
  author = {Prüfer, Kay},
  date = {2018-12-15},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {34},
  pages = {4165--4171},
  publisher = {{Oxford Academic}},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/bty507},
  url = {https://academic.oup.com/bioinformatics/article/34/24/4165/5042170},
  urldate = {2020-02-27},
  abstract = {AbstractMotivation.  The study of ancient genomes can elucidate the evolutionary past. However, analyses are complicated by base-modifications in ancient DNA mo},
  langid = {english},
  number = {24}
}

@article{zhouAntCallerAccurateVariant2017,
  title = {{{AntCaller}}: An Accurate Variant Caller Incorporating Ancient {{DNA}} Damage},
  shorttitle = {{{AntCaller}}},
  author = {Zhou, Boyan and Wen, Shaoqing and Wang, Lingxiang and Jin, Li and Li, Hui and Zhang, Hong},
  date = {2017-12-01},
  journaltitle = {Molecular Genetics and Genomics},
  shortjournal = {Mol Genet Genomics},
  volume = {292},
  pages = {1419--1430},
  issn = {1617-4623},
  doi = {10.1007/s00438-017-1358-5},
  url = {https://doi.org/10.1007/s00438-017-1358-5},
  urldate = {2020-10-09},
  abstract = {Ancient DNA obtained from ancient samples, such as sediments, bones, and teeth, is an important genetic resource that can be used to reconstruct an evolutional history of humans, animals, and plants. The application of high-throughput sequencing enables the research of ancient DNA to be conducted in a whole genome scale. However, post-mortem DNA damage mainly caused by deamination of cytosine to uracil (or methylated cytosine to thymine) may confound the variant calling and downstream analysis. In this article, we develop a Python program to implement a new variant caller, “AntCaller”, which extracts the information on nucleotide substitutions from sequencing data and calculates the probability of each genotype based on a Bayesian rule. Through both simulation studies and real data analyses, it was shown that our method reduced the false discovery rate caused by nucleotide misincorporations and outperformed two mainstream variant callers (i.e., GATK and SAMtools) in terms of calling accuracy. In a real application with serious DNA damage, AntCaller still outperformed GATK and SAMtools combined with quality score recalling.},
  langid = {english},
  number = {6}
}


@article{cahillGenomicEvidenceWidespread2018,
  title = {Genomic {{Evidence}} of {{Widespread Admixture}} from {{Polar Bears}} into {{Brown Bears}} during the {{Last Ice Age}}},
  author = {Cahill, James A. and Heintzman, Peter D. and Harris, Kelley and Teasdale, Matthew D. and Kapp, Joshua and Soares, Andre E. R. and Stirling, Ian and Bradley, Daniel and Edwards, Ceiridwen J. and Graim, Kiley and Kisleika, Aliaksandr A. and Malev, Alexander V. and Monaghan, Nigel and Green, Richard E. and Shapiro, Beth},
  date = {2018-05-01},
  journaltitle = {Molecular Biology and Evolution},
  shortjournal = {Mol Biol Evol},
  volume = {35},
  pages = {1120--1129},
  publisher = {{Oxford Academic}},
  issn = {0737-4038},
  doi = {10.1093/molbev/msy018},
  url = {https://academic.oup.com/mbe/article/35/5/1120/4844088},
  urldate = {2020-08-20},
  abstract = {Abstract.  Recent genomic analyses have provided substantial evidence for past periods of gene flow from polar bears (Ursus maritimus) into Alaskan brown bears},
  langid = {english},
  number = {5}
}

@article{poulletAssessingDNASequence2020,
  title = {Assessing {{DNA Sequence Alignment Methods}} for {{Characterizing Ancient Genomes}} and {{Methylomes}}},
  author = {Poullet, Marine and Orlando, Ludovic},
  date = {2020},
  journaltitle = {Frontiers in Ecology and Evolution},
  shortjournal = {Front. Ecol. Evol.},
  volume = {8},
  publisher = {{Frontiers}},
  issn = {2296-701X},
  doi = {10.3389/fevo.2020.00105},
  url = {https://www.frontiersin.org/articles/10.3389/fevo.2020.00105/full},
  urldate = {2020-08-20},
  abstract = {Applying high-throughput DNA sequencing technologies to the ancient DNA molecules preserved in subfossil material can provide genetic information from past individuals, populations and communities at the genomic scale. The combination of dedicated statistical techniques and specific molecular tools aimed at reducing the impact of post-mortem DNA damage can also help recover epigenetic data from ancient individuals. However, the capacity of different sequence aligners to identify ultrashort and deaminated ancient DNA templates, and their impact on the characterization of ancient methylomes, remain overlooked. In this study, we use both simulated and real ancient DNA sequence data to benchmark the performance of the read alignment tools most commonly used in ancient DNA research. We identify a read alignment strategy making use of the Bowtie2 aligner that substantially reduce computational times but shows increased sensitivity relative to previous recommendations based on the BWA aligner. This strategy significantly improves the genome coverage especially when DNA templates are shorter than 90bp, as is typically the case for ancient DNA. It also impacts on ancient DNA methylation estimates as it maximizes coverage improvement within CpG dinucleotide contexts, which hold the vast majority of DNA methylation marks in mammals. Our work contributes to improve the accuracy of DNA methylation maps and to maximize the amount of recoverable genetic information from archaeological and subfossil material. As the molecular complexity of ancient DNA libraries is generally limited, the mapping strategy recommended here is essential to both limit sequencing costs and sample destruction.},
  keywords = {Alignment,ANCIENT DNA,coverage,DNA Damage,DNA Methylation,Genome,Mapping,methylome},
  langid = {english}
}


@article{liAligningSequenceReads2013,
  title = {Aligning Sequence Reads, Clone Sequences and Assembly Contigs with {{BWA}}-{{MEM}}},
  author = {Li, Heng},
  date = {2013-03-16},
  url = {http://arxiv.org/abs/1303.3997},
  urldate = {2019-10-09},
  abstract = {Summary: BWA-MEM is a new alignment algorithm for aligning sequence reads or long query sequences against a large reference genome such as human. It automatically chooses between local and end-to-end alignments, supports paired-end reads and performs chimeric alignment. The algorithm is robust to sequencing errors and applicable to a wide range of sequence lengths from 70bp to a few megabases. For mapping 100bp sequences, BWA-MEM shows better performance than several state-of-art read aligners to date. Availability and implementation: BWA-MEM is implemented as a component of BWA, which is available at http://github.com/lh3/bwa. Contact: hengli@broadinstitute.org},
  annotation = {Comment: 3 pages and 1 color figure},
  archivePrefix = {arXiv},
  eprint = {1303.3997},
  eprinttype = {arxiv},
  keywords = {Quantitative Biology - Genomics},
  primaryClass = {q-bio}
}

@article{liFastAccurateLongread2010,
  title = {Fast and Accurate Long-Read Alignment with {{Burrows}}–{{Wheeler}} Transform},
  author = {Li, Heng and Durbin, Richard},
  date = {2010-03-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {26},
  pages = {589--595},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btp698},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2828108/},
  urldate = {2017-09-21},
  abstract = {Motivation: Many programs for aligning short sequencing reads to a reference genome have been developed in the last 2 years. Most of them are very efficient for short reads but inefficient or not applicable for reads {$>$}200 bp because the algorithms are heavily and specifically tuned for short queries with low sequencing error rate. However, some sequencing platforms already produce longer reads and others are expected to become available soon. For longer reads, hashing-based software such as BLAT and SSAHA2 remain the only choices. Nonetheless, these methods are substantially slower than short-read aligners in terms of aligned bases per unit time., Results: We designed and implemented a new algorithm, Burrows-Wheeler Aligner's Smith-Waterman Alignment (BWA-SW), to align long sequences up to 1 Mb against a large sequence database (e.g. the human genome) with a few gigabytes of memory. The algorithm is as accurate as SSAHA2, more accurate than BLAT, and is several to tens of times faster than both., Availability: http://bio-bwa.sourceforge.net, Contact: rd@sanger.ac.uk},
  eprint = {20080505},
  eprinttype = {pmid},
  note = {03191},
  number = {5},
  pmcid = {PMC2828108}
}


@article{gu_circlize_2014,
	title = {circlize implements and enhances circular visualization in R},
	volume = {30},
	issn = {1367-4803},
	url = {https://academic.oup.com/bioinformatics/article/30/19/2811/2422259},
	doi = {10.1093/bioinformatics/btu393},
	abstract = {Summary: Circular layout is an efficient way for the visualization of huge amounts of genomic information. Here we present the circlize package, which provides an implementation of circular layout generation in R as well as an enhancement of available software. The flexibility of this package is based on the usage of low-level graphics functions such that self-defined high-level graphics can be easily implemented by users for specific purposes. Together with the seamless connection between the powerful computational and visual environment in R, circlize gives users more convenience and freedom to design figures for better understanding genomic patterns behind multi-dimensional data. Availability and implementation:circlize is available at the Comprehensive R Archive Network ({CRAN}): http://cran.r-project.org/web/packages/circlize/Contact:b.brors@dkfz.{deSupplementary} information:Supplementary data are available at Bioinformatics online.},
	pages = {2811--2812},
	number = {19},
	journaltitle = {Bioinformatics},
	shortjournal = {Bioinformatics},
	author = {Gu, Zuguang and Gu, Lei and Eils, Roland and Schlesner, Matthias and Brors, Benedikt},
	urldate = {2018-02-15},
	date = {2014-10-01},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\s2978925\\Zotero\\storage\\QNMCMLZ3\\Gu et al. - 2014 - circlize implements and enhances circular visualiz.pdf:application/pdf;Snapshot:C\:\\Users\\s2978925\\Zotero\\storage\\BGPZ752M\\2422259.html:text/html}
}

@article{bushnell_bbmap:_2014,
	title = {{BBMap}: A Fast, Accurate, Splice-Aware Aligner},
	url = {https://pubarchive.lbl.gov/islandora/object/ir%3A1005301/},
	shorttitle = {{BBMap}},
	author = {Bushnell, Brian},
	urldate = {2017-11-23},
	date = {2014},
	file = {Full Text PDF:C\:\\Users\\s2978925\\Zotero\\storage\\M5N49MIK\\Bushnell - 2014 - BBMap A Fast, Accurate, Splice-Aware Aligner.pdf:application/pdf;Snapshot:C\:\\Users\\s2978925\\Zotero\\storage\\JUS7HHEG\\ir1005301.html:text/html}
}

@article{garrison_haplotype-based_2012,
  title = {Haplotype-Based Variant Detection from Short-Read Sequencing},
  shorttitle = {Haplotype-Based Variant Detection from Short-Read Sequencing},
  timestamp = {2016-01-10T13:39:31Z},
  journaltitle = {arXiv preprint arXiv:1207.3907},
  author = {Garrison, Erik and Marth, Gabor},
  date = {2012}
}
@article{lawrence_software_2013,
  title = {Software for {{Computing}} and {{Annotating Genomic Ranges}}},
  volume = {9},
  url = {http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1003118},
  doi = {10.1371/journal.pcbi.1003118},
  timestamp = {2016-11-04T03:48:43Z},
  number = {8},
  journaltitle = {PLoS Computational Biology},
  author = {Lawrence, Michael and Huber, Wolfgang and Pagès, Hervé and Aboyoun, Patrick and Carlson, Marc and Gentleman, Robert and Morgan, Martin and Carey, Vincent},
  date = {2013}
}


@article{obenchain_variantannotation:_2014,
  title = {{{VariantAnnotation}}: A {{Bioconductor}} Package for Exploration and Annotation of Genetic Variants},
  volume = {30},
  issn = {1367-4803},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4080743/},
  doi = {10.1093/bioinformatics/btu168},
  shorttitle = {{{VariantAnnotation}}},
  abstract = {Summary:
VariantAnnotation is an R / Bioconductor
package for the exploration and annotation of genetic variants. Capabilities exist for
reading, writing and filtering variant call format (VCF) files.
VariantAnnotation allows ready access to additional R
/ Bioconductor facilities for advanced statistical analysis, data
transformation, visualization and integration with diverse genomic resources., Availability and implementation: This package is implemented in R and
available for download at the Bioconductor Web site (http://bioconductor.org/packages/2.13/bioc/html/VariantAnnotation.html).
The package contains extensive help pages for individual functions and a
‘vignette’ outlining typical work flows; it is made available under the open
source ‘Artistic-2.0’ license. Version 1.9.38 was used in this article., 
Contact:
vobencha@fhcrc.org},
  timestamp = {2017-08-28T00:58:48Z},
  number = {14},
  journaltitle = Bioinformatics,
  author = {Obenchain, Valerie and Lawrence, Michael and Carey, Vincent and Gogarten, Stephanie and Shannon, Paul and Morgan, Martin},
  urldate = {2017-08-28},
  date = {2014-07-15},
  pages = {2076--2078},
  eprinttype = {pmid},
  eprint = {24681907},
  pmcid = {PMC4080743}
}



@article{ruden_using_2012,
  title = {Using {{{\emph{Drosophila}}}}{\emph{ Melanogaster}} as a Model for Genotoxic Chemical Mutational Studies with a New Program, {{SnpSift}}},
  volume = {3},
  url = {http://journal.frontiersin.org/article/10.3389/fgene.2012.00035/full},
  doi = {10.3389/fgene.2012.00035},
  abstract = {This paper describes a new program SnpSift for filtering differential DNA sequence variants between two or more experimental genomes after genotoxic chemical exposure. Here, we illustrate how SnpSift can be used to identify candidate phenotype-relevant variants including single nucleotide polymorphisms, multiple nucleotide polymorphisms, insertions, and deletions (InDels) in mutant strains isolated from genome-wide chemical mutagenesis of Drosophila melanogaster. First, the genomes of two independently isolated mutant fly strains that are allelic for a novel recessive male-sterile locus generated by genotoxic chemical exposure were sequenced using the Illumina next-generation DNA sequencer to obtain 20- to 29-fold coverage of the euchromatic sequences. The sequencing reads were processed and variants were called using standard bioinformatic tools. Next, SnpEff was used to annotate all sequence variants and their potential mutational effects on associated genes. Then, SnpSift was used to filter and select differential variants that potentially disrupt a common gene in the two allelic mutant strains. The potential causative DNA lesions were partially validated by capillary sequencing of polymerase chain reaction-amplified DNA in the genetic interval as defined by meiotic mapping and deletions that remove defined regions of the chromosome. Of the five candidate genes located in the genetic interval, the Pka-like gene CG12069 was found to carry a separate pre-mature stop codon mutation in each of the two allelic mutants whereas the other four candidate genes within the interval have wild-type sequences. The Pka-like gene is therefore a strong candidate gene for the male-sterile locus. These results demonstrate that combining SnpEff and SnpSift can expedite the identification of candidate phenotype-causative mutations in chemically mutagenized Drosophila strains. This technique can also be used to characterize the variety of mutations generated by genotoxic chemicals.},
  timestamp = {2017-08-15T01:06:07Z},
  journaltitle = Toxicogenomics,
  author = {Ruden, Douglas Mark and Cingolani, Pablo and Patel, Viral M. and Coon, Melissa and Nguyen, Tung and Land, Susan J. and Lu, Xiangyi},
  urldate = {2016-11-04},
  date = {2012},
  pages = {35},
  keywords = {Drosophila melanogaster,next-generation DNA sequencing,personal genomes,whole-genome SNP analysis}
}




@article{karssen_genabel_2016,
  title = {The {{GenABEL Project}} for Statistical Genomics},
  volume = {5},
  issn = {2046-1402},
  url = {http://f1000research.com/articles/5-914/v1},
  doi = {10.12688/f1000research.8733.1},
  timestamp = {2017-08-28T00:13:44Z},
  langid = {english},
  journaltitle = F1000Research,
  author = {Karssen, Lennart C. and van Duijn, Cornelia M. and Aulchenko, Yurii S.},
  urldate = {2017-08-28},
  date = {2016-05-19},
  pages = {914},
  options = {useprefix=true}
}


@article{aulchenko_genabel:_2007,
  title = {{{GenABEL}}: An {{R}} Library for Genome-Wide Association Analysis},
  volume = {23},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btm108},
  shorttitle = {{{GenABEL}}},
  abstract = {Here we describe an R library for genome-wide association (GWA) analysis. It implements effective storage and handling of GWA data, fast procedures for genetic data quality control, testing of association of single nucleotide polymorphisms with binary or quantitative traits, visualization of results and also provides easy interfaces to standard statistical and graphical procedures implemented in base R and special R libraries for genetic analysis. We evaluated GenABEL using one simulated and two real data sets. We conclude that GenABEL enables the analysis of GWA data on desktop computers.
AVAILABILITY: http://cran.r-project.org.},
  timestamp = {2017-08-28T00:32:04Z},
  langid = {english},
  number = {10},
  journaltitle = {Bioinformatics (Oxford, England)},
  shortjournal = Bioinformatics,
  author = {Aulchenko, Yurii S. and Ripke, Stephan and Isaacs, Aaron and van Duijn, Cornelia M.},
  date = {2007-05-15},
  pages = {1294--1296},
  keywords = {Computational biology,Computer Simulation,Gene Library,Genome,Genome; Human,Haplotypes,Humans,Information Storage and Retrieval,Oligonucleotide Array Sequence Analysis,Polymorphism; Single Nucleotide,Software},
  options = {useprefix=true},
  eprinttype = {pmid},
  eprint = {17384015}
}

@article{okonechnikov_qualimap_2016,
  title = {Qualimap 2: Advanced Multi-Sample Quality Control for High-Throughput Sequencing Data},
  volume = {32},
  issn = {1367-4803},
  url = {https://academic.oup.com/bioinformatics/article/32/2/292/1744356/Qualimap-2-advanced-multi-sample-quality-control},
  doi = {10.1093/bioinformatics/btv566},
  shorttitle = {Qualimap 2},
  abstract = {Motivation: Detection of random errors and systematic biases is a crucial step of a robust pipeline for processing high-throughput sequencing (HTS) data. Bioinformatics software tools capable of performing this task are available, either for general analysis of HTS data or targeted to a specific sequencing technology. However, most of the existing QC instruments only allow processing of one sample at a time.Results: Qualimap 2 represents a next step in the QC analysis of HTS data. Along with comprehensive single-sample analysis of alignment data, it includes new modes that allow simultaneous processing and comparison of multiple samples. As with the first version, the new features are available via both graphical and command line interface. Additionally, it includes a large number of improvements proposed by the user community.Availability and implementation: The implementation of the software along with documentation is freely available at http://www.qualimap.org.Contact:meyer@mpiib-berlin.mpg.deSupplementary information:Supplementary data are available at Bioinformatics online.},
  timestamp = {2017-07-28T04:38:26Z},
  number = {2},
  journaltitle = Bioinformatics,
  author = {Okonechnikov, Konstantin and Conesa, Ana and García-Alcalde, Fernando},
  urldate = {2017-07-28},
  date = {2016-01-15},
  pages = {292--294}
}
@article{faust_samblaster:_2014,
  title = {{{SAMBLASTER}}: Fast Duplicate Marking and Structural Variant Read Extraction},
  volume = {30},
  issn = {1367-4803},
  url = {https://academic.oup.com/bioinformatics/article/30/17/2503/2748175/SAMBLASTER-fast-duplicate-marking-and-structural},
  doi = {10.1093/bioinformatics/btu314},
  shorttitle = {{{SAMBLASTER}}},
  abstract = {Motivation: Illumina DNA sequencing is now the predominant source of raw genomic data, and data volumes are growing rapidly. Bioinformatic analysis pipelines are having trouble keeping pace. A common bottleneck in such pipelines is the requirement to read, write, sort and compress large BAM files multiple times.Results: We present SAMBLASTER, a tool that reduces the number of times such costly operations are performed. SAMBLASTER is designed to mark duplicates in read-sorted SAM files as a piped post-pass on DNA aligner output before it is compressed to BAM. In addition, it can simultaneously output into separate files the discordant read-pairs and/or split-read mappings used for structural variant calling. As an alignment post-pass, its own runtime overhead is negligible, while dramatically reducing overall pipeline complexity and runtime. As a stand-alone duplicate marking tool, it performs significantly better than PICARD or SAMBAMBA in terms of both speed and memory usage, while achieving nearly identical results.Availability and implementation: SAMBLASTER is open-source C++ code and freely available for download from https://github.com/GregoryFaust/samblaster.Contact:imh4y@virginia.edu},
  timestamp = {2017-07-23T11:06:29Z},
  number = {17},
  journaltitle = Bioinformatics,
  author = {Faust, Gregory G. and Hall, Ira M.},
  urldate = {2017-07-23},
  date = {2014-09-01},
  pages = {2503--2505}
}

@article{ewels_multiqc:_2016,
  title = {{{MultiQC}}: Summarize Analysis Results for Multiple Tools and Samples in a Single Report},
  volume = {32},
  issn = {1367-4803},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5039924/},
  doi = {10.1093/bioinformatics/btw354},
  shorttitle = {{{MultiQC}}},
  abstract = {Motivation: Fast and accurate quality control is essential for studies involving next-generation sequencing data. Whilst numerous tools exist to quantify QC metrics, there is no common approach to flexibly integrate these across tools and large sample sets. Assessing analysis results across an entire project can be time consuming and error prone; batch effects and outlier samples can easily be missed in the early stages of analysis., Results: We present MultiQC, a tool to create a single report visualising output from multiple tools across many samples, enabling global trends and biases to be quickly identified. MultiQC can plot data from many common bioinformatics tools and is built to allow easy extension and customization., Availability and implementation: MultiQC is available with an GNU GPLv3 license on GitHub, the Python Package Index and Bioconda. Documentation and example reports are available at 
http://multiqc.info, Contact:
phil.ewels@scilifelab.se},
  timestamp = {2017-07-19T02:52:02Z},
  number = {19},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  author = {Ewels, Philip and Magnusson, Måns and Lundin, Sverker and Käller, Max},
  urldate = {2017-07-19},
  date = {2016-10-01},
  pages = {3047--3048},
  eprinttype = {pmid},
  eprint = {27312411},
  pmcid = {PMC5039924}
}


@article{defilippoQuantifyingReducingSpurious2018,
  title = {Quantifying and Reducing Spurious Alignments for the Analysis of Ultra-Short Ancient {{DNA}} Sequences},
  author = {de Filippo, Cesare and Meyer, Matthias and Prüfer, Kay},
  date = {2018-10-25},
  journaltitle = {BMC Biology},
  shortjournal = {BMC Biology},
  volume = {16},
  pages = {121},
  issn = {1741-7007},
  doi = {10.1186/s12915-018-0581-9},
  url = {https://doi.org/10.1186/s12915-018-0581-9},
  urldate = {2020-02-26},
  abstract = {The study of ancient DNA is hampered by degradation, resulting in short DNA fragments. Advances in laboratory methods have made it possible to retrieve short DNA fragments, thereby improving access to DNA preserved in highly degraded, ancient material. However, such material contains large amounts of microbial contamination in addition to DNA fragments from the ancient organism. The resulting mixture of sequences constitutes a challenge for computational analysis, since microbial sequences are hard to distinguish from the ancient sequences of interest, especially when they are short.},
  number = {1},
  options = {useprefix=true}
}

@article{guntherPresenceImpactReference2019,
  title = {The Presence and Impact of Reference Bias on Population Genomic Studies of Prehistoric Human Populations},
  author = {Günther, Torsten and Nettelblad, Carl},
  date = {2019-07-26},
  journaltitle = {PLOS Genetics},
  shortjournal = {PLOS Genetics},
  volume = {15},
  pages = {e1008302},
  publisher = {{Public Library of Science}},
  issn = {1553-7404},
  doi = {10.1371/journal.pgen.1008302},
  url = {https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1008302},
  urldate = {2020-02-26},
  abstract = {Haploid high quality reference genomes are an important resource in genomic research projects. A consequence is that DNA fragments carrying the reference allele will be more likely to map successfully, or receive higher quality scores. This reference bias can have effects on downstream population genomic analysis when heterozygous sites are falsely considered homozygous for the reference allele. In palaeogenomic studies of human populations, mapping against the human reference genome is used to identify endogenous human sequences. Ancient DNA studies usually operate with low sequencing coverages and fragmentation of DNA molecules causes a large proportion of the sequenced fragments to be shorter than 50 bp—reducing the amount of accepted mismatches, and increasing the probability of multiple matching sites in the genome. These ancient DNA specific properties are potentially exacerbating the impact of reference bias on downstream analyses, especially since most studies of ancient human populations use pseudo-haploid data, i.e. they randomly sample only one sequencing read per site. We show that reference bias is pervasive in published ancient DNA sequence data of prehistoric humans with some differences between individual genomic regions. We illustrate that the strength of reference bias is negatively correlated with fragment length. Most genomic regions we investigated show little to no mapping bias but even a small proportion of sites with bias can impact analyses of those particular loci or slightly skew genome-wide estimates. Therefore, reference bias has the potential to cause minor but significant differences in the results of downstream analyses such as population allele sharing, heterozygosity estimates and estimates of archaic ancestry. These spurious results highlight how important it is to be aware of these technical artifacts and that we need strategies to mitigate the effect. Therefore, we suggest some post-mapping filtering strategies to resolve reference bias which help to reduce its impact substantially.},
  keywords = {Alleles,Ancient DNA,Genomic libraries,Genomics statistics,Heterozygosity,Molecular genetics,Paleogenetics,Population genetics},
  langid = {english},
  number = {7}
}

@article{jeongCharacterizingGeneticHistory2018,
  title = {Characterizing the Genetic History of Admixture across Inner {{Eurasia}}},
  author = {Jeong, Choongwon and Balanovsky, Oleg and Lukianova, Elena and Kahbatkyzy, Nurzhibek and Flegontov, Pavel and Zaporozhchenko, Valery and Immel, Alexander and Wang, Chuan-Chao and Ixan, Olzhas and Khussainova, Elmira and Bekmanov, Bakhytzhan and Zaibert, Victor and Lavryashina, Maria and Pocheshkhova, Elvira and Yusupov, Yuldash and Agdzhoyan, Anastasiya and Sergey, Koshel and Bukin, Andrei and Nymadawa, Pagbajabyn and Churnosov, Michail and Skhalyakho, Roza and Daragan, Denis and Bogunov, Yuri and Bogunova, Anna and Shtrunov, Alexandr and Dubova, Nadezda and Zhabagin, Maxat and Yepiskoposyan, Levon and Churakov, Vladimir and Pislegin, Nikolay and Damba, Larissa and Saroyants, Ludmila and Dibirova, Khadizhat and Artamentova, Lubov and Utevska, Olga and Idrisov, Eldar and Kamenshchikova, Evgeniya and Evseeva, Irina and Metspalu, Mait and Robbeets, Martine and Djansugurova, Leyla and Balanovska, Elena and Schiffels, Stephan and Haak, Wolfgang and Reich, David and Krause, Johannes},
  date = {2018-05-23},
  journaltitle = {bioRxiv},
  pages = {327122},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/327122},
  url = {https://www.biorxiv.org/content/10.1101/327122v1},
  urldate = {2020-02-26},
  abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}The indigenous populations of inner Eurasia, a huge geographic region covering the central Eurasian steppe and the northern Eurasian taiga and tundra, harbor tremendous diversity in their genes, cultures and languages. In this study, we report novel genome-wide data for 763 individuals from Armenia, Georgia, Kazakhstan, Moldova, Mongolia, Russia, Tajikistan, Ukraine, and Uzbekistan. We furthermore report genome-wide data of two Eneolithic individuals (∽5,400 years before present) associated with the Botai culture in northern Kazakhstan. We find that inner Eurasian populations are structured into three distinct admixture clines stretching between various western and eastern Eurasian ancestries. This genetic separation is well mirrored by geography. The ancient Botai genomes suggest yet another layer of admixture in inner Eurasia that involves Mesolithic hunter-gatherers in Europe, the Upper Paleolithic southern Siberians and East Asians. Admixture modeling of ancient and modern populations suggests an overwriting of this ancient structure in the Altai-Sayan region by migrations of western steppe herders, but partial retaining of this ancient North Eurasian-related cline further to the North. Finally, the genetic structure of Caucasus populations highlights a role of the Caucasus Mountains as a barrier to gene flow and suggests a post-Neolithic gene flow into North Caucasus populations from the steppe.{$<$}/p{$>$}},
  langid = {english}
}

@article{jonssonMapDamage2FastApproximate2013,
  title = {{{mapDamage2}}.0: Fast Approximate {{Bayesian}} Estimates of Ancient {{DNA}} Damage Parameters},
  shorttitle = {{{mapDamage2}}.0},
  author = {Jónsson, Hákon and Ginolhac, Aurélien and Schubert, Mikkel and Johnson, Philip L. F. and Orlando, Ludovic},
  date = {2013-07-01},
  journaltitle = {Bioinformatics},
  shortjournal = {Bioinformatics},
  volume = {29},
  pages = {1682--1684},
  publisher = {{Oxford Academic}},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btt193},
  url = {https://academic.oup.com/bioinformatics/article/29/13/1682/184965},
  urldate = {2020-02-26},
  abstract = {Abstract.  Motivation: Ancient DNA (aDNA) molecules in fossilized bones and teeth, coprolites, sediments, mummified specimens and museum collections represent f},
  langid = {english},
  number = {13}
}

@article{martinianoRemovingReferenceBias2019,
  title = {Removing Reference Bias in Ancient {{DNA}} Data Analysis by Mapping to a Sequence Variation Graph},
  author = {Martiniano, Rui and Garrison, Erik and Jones, Eppie R. and Manica, Andrea and Durbin, Richard},
  date = {2019-09-26},
  journaltitle = {bioRxiv},
  pages = {782755},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/782755},
  url = {https://www.biorxiv.org/content/10.1101/782755v1},
  urldate = {2020-02-26},
  abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}h3{$>$}Background{$<$}/h3{$>$} {$<$}p{$>$}During the last decade, the analysis of ancient DNA (aDNA) sequence has become a powerful tool for the study of past human populations. However, the degraded nature of aDNA means that aDNA sequencing reads are short, single-ended and frequently mutated by post-mortem chemical modifications. All these features decrease read mapping accuracy and increase reference bias, in which reads containing non-reference alleles are less likely to be mapped than those containing reference alleles. Recently, alternative approaches for read mapping and genetic variation analysis have been developed that replace the linear reference by a variation graph which includes all the alternative variants at each genetic locus. Here, we evaluate the use of variation graph software vg to avoid reference bias for ancient DNA.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$>$} {$<$}p{$>$}We used vg to align multiple previously published aDNA samples to a variation graph containing 1000 Genome Project variants, and compared these with the same data aligned with bwa to the human linear reference genome. We show that use of vg leads to a much more balanced allelic representation at polymorphic sites and better variant detection in comparison with bwa, especially in the presence of post-mortem changes, effectively removing reference bias. A recently published approach that filters bwa alignments using modified reads also removes bias, but has lower sensitivity than vg.{$<$}/p{$><$}h3{$>$}Conclusions{$<$}/h3{$>$} {$<$}p{$>$}Our findings demonstrate that aligning aDNA sequences to variation graphs allows recovering a higher fraction of non-reference variation and effectively mitigates the impact of reference bias in population genetics analyses using aDNA, while retaining mapping sensitivity.{$<$}/p{$>$}},
  langid = {english}
}

@article{peltzerEAGEREfficientAncient2016,
  title = {{{EAGER}}: Efficient Ancient Genome Reconstruction},
  shorttitle = {{{EAGER}}},
  author = {Peltzer, Alexander and Jäger, Günter and Herbig, Alexander and Seitz, Alexander and Kniep, Christian and Krause, Johannes and Nieselt, Kay},
  date = {2016-03-31},
  journaltitle = {Genome Biology},
  shortjournal = {Genome Biol},
  volume = {17},
  issn = {1474-7596},
  doi = {10.1186/s13059-016-0918-z},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4815194/},
  urldate = {2020-02-26},
  abstract = {Background
The automated reconstruction of genome sequences in ancient genome analysis is a multifaceted process.

Results
Here we introduce EAGER, a time-efficient pipeline, which greatly simplifies the analysis of large-scale genomic data sets. EAGER provides features to preprocess, map, authenticate, and assess the quality of ancient DNA samples. Additionally, EAGER comprises tools to genotype samples to discover, filter, and analyze variants.

Conclusions
EAGER encompasses both state-of-the-art tools for each step as well as new complementary tools tailored for ancient DNA data within a single integrated solution in an easily accessible format.

Electronic supplementary material
The online version of this article (doi:10.1186/s13059-016-0918-z) contains supplementary material, which is available to authorized users.},
  eprint = {27036623},
  eprinttype = {pmid},
  pmcid = {PMC4815194}
}

@article{schubertImprovingAncientDNA2012,
  title = {Improving Ancient {{DNA}} Read Mapping against Modern Reference Genomes},
  author = {Schubert, Mikkel and Ginolhac, Aurelien and Lindgreen, Stinus and Thompson, John F. and AL-Rasheid, Khaled AS and Willerslev, Eske and Krogh, Anders and Orlando, Ludovic},
  date = {2012-05-10},
  journaltitle = {BMC Genomics},
  shortjournal = {BMC Genomics},
  volume = {13},
  pages = {178},
  issn = {1471-2164},
  doi = {10.1186/1471-2164-13-178},
  url = {https://doi.org/10.1186/1471-2164-13-178},
  urldate = {2020-02-26},
  abstract = {Next-Generation Sequencing has revolutionized our approach to ancient DNA (aDNA) research, by providing complete genomic sequences of ancient individuals and extinct species. However, the recovery of genetic material from long-dead organisms is still complicated by a number of issues, including post-mortem DNA damage and high levels of environmental contamination. Together with error profiles specific to the type of sequencing platforms used, these specificities could limit our ability to map sequencing reads against modern reference genomes and therefore limit our ability to identify endogenous ancient reads, reducing the efficiency of shotgun sequencing aDNA.},
  number = {1}
}

@article{sedlazeckNextGenMapFastAccurate2013,
  title = {{{NextGenMap}}: Fast and Accurate Read Mapping in Highly Polymorphic Genomes},
  shorttitle = {{{NextGenMap}}},
  author = {Sedlazeck, Fritz J. and Rescheneder, Philipp and von Haeseler, Arndt},
  date = {2013-11-01},
  journaltitle = {Bioinformatics (Oxford, England)},
  shortjournal = {Bioinformatics},
  volume = {29},
  pages = {2790--2791},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btt468},
  abstract = {SUMMARY: When choosing a read mapper, one faces the trade off between speed and the ability to map reads in highly polymorphic regions. Here, we report NextGenMap, a fast and accurate read mapper, which reduces this dilemma. NextGenMap aligns reads reliably to a reference genome even when the sequence difference between target and reference genome is large, i.e. highly polymorphic genome. At the same time, NextGenMap outperforms current mapping methods with respect to runtime and to the number of correctly mapped reads. NextGenMap efficiently uses the available hardware by exploiting multi-core CPUs as well as graphic cards (GPUs), if available. In addition, NextGenMap handles automatically any read data independent of read length and sequencing technology.
AVAILABILITY: NextGenMap source code and documentation are available at: http://cibiv.github.io/NextGenMap/.
CONTACT: fritz.sedlazeck@univie.ac.at.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
  eprint = {23975764},
  eprinttype = {pmid},
  keywords = {Genome,Genomics,High-Throughput Nucleotide Sequencing,Polymorphism; Genetic,Sequence Alignment,Software},
  langid = {english},
  number = {21},
  options = {useprefix=true}
}

@article{seitzImprovingAncientDNA2017a,
  title = {Improving Ancient {{DNA}} Genome Assembly},
  author = {Seitz, Alexander and Nieselt, Kay},
  date = {2017-04-05},
  journaltitle = {PeerJ},
  shortjournal = {PeerJ},
  volume = {5},
  pages = {e3126},
  publisher = {{PeerJ Inc.}},
  issn = {2167-8359},
  doi = {10.7717/peerj.3126},
  url = {https://peerj.com/articles/3126},
  urldate = {2020-02-26},
  abstract = {Most reconstruction methods for genomes of ancient origin that are used today require a closely related reference. In order to identify genomic rearrangements or the deletion of whole genes, de novo assembly has to be used. However, because of inherent problems with ancient DNA, its de novo assembly is highly complicated. In order to tackle the diversity in the length of the input reads, we propose a two-layer approach, where multiple assemblies are generated in the first layer, which are then combined in the second layer. We used this two-layer assembly to generate assemblies for two different ancient samples and compared the results to current de novo assembly approaches. We are able to improve the assembly with respect to the length of the contigs and can resolve more repetitive regions.},
  langid = {english}
}

@article{taronTestingAlignmentParameters2018,
  title = {Testing of {{Alignment Parameters}} for {{Ancient Samples}}: {{Evaluating}} and {{Optimizing Mapping Parameters}} for {{Ancient Samples Using}} the {{TAPAS Tool}}},
  shorttitle = {Testing of {{Alignment Parameters}} for {{Ancient Samples}}},
  author = {Taron, Ulrike H. and Lell, Moritz and Barlow, Axel and Paijmans, Johanna L. A.},
  date = {2018-03-13},
  journaltitle = {Genes},
  shortjournal = {Genes (Basel)},
  volume = {9},
  issn = {2073-4425},
  doi = {10.3390/genes9030157},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5867878/},
  urldate = {2020-02-26},
  abstract = {High-throughput sequence data retrieved from ancient or other degraded samples has led to unprecedented insights into the evolutionary history of many species, but the analysis of such sequences also poses specific computational challenges. The most commonly used approach involves mapping sequence reads to a reference genome. However, this process becomes increasingly challenging with an elevated genetic distance between target and reference or with the presence of contaminant sequences with high sequence similarity to the target species. The evaluation and testing of mapping efficiency and stringency are thus paramount for the reliable identification and analysis of ancient sequences. In this paper, we present ‘TAPAS’, (Testing of Alignment Parameters for Ancient Samples), a computational tool that enables the systematic testing of mapping tools for ancient data by simulating sequence data reflecting the properties of an ancient dataset and performing test runs using the mapping software and parameter settings of interest. We showcase TAPAS by using it to assess and improve mapping strategy for a degraded sample from a banded linsang (Prionodon linsang), for which no closely related reference is currently available. This enables a 1.8-fold increase of the number of mapped reads without sacrificing mapping specificity. The increase of mapped reads effectively reduces the need for additional sequencing, thus making more economical use of time, resources, and sample material.},
  eprint = {29533977},
  eprinttype = {pmid},
  number = {3},
  pmcid = {PMC5867878}
}

@article{turkiMaxSSmapGPUProgram2014,
  title = {{{MaxSSmap}}: A {{GPU}} Program for Mapping Divergent Short Reads to Genomes with the Maximum Scoring Subsequence},
  shorttitle = {{{MaxSSmap}}},
  author = {Turki, Turki and Roshan, Usman},
  date = {2014-11-15},
  journaltitle = {BMC Genomics},
  shortjournal = {BMC Genomics},
  volume = {15},
  pages = {969},
  issn = {1471-2164},
  doi = {10.1186/1471-2164-15-969},
  url = {https://doi.org/10.1186/1471-2164-15-969},
  urldate = {2020-02-26},
  abstract = {Programs based on hash tables and Burrows-Wheeler are very fast for mapping short reads to genomes but have low accuracy in the presence of mismatches and gaps. Such reads can be aligned accurately with the Smith-Waterman algorithm but it can take hours and days to map millions of reads even for bacteria genomes.},
  number = {1}
}


